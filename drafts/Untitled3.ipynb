{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38dff345-82a5-4a84-bf71-5d08b3144199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open('SDGTargets.txt', 'r') as f:\n",
    "    hypothesis_candidates = pd.read_table(f)\n",
    "    #print(hypothesis_candidates)\n",
    "\n",
    "hypothesis_candidates = hypothesis_candidates['hypothesis'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d82073a-2635-4dae-a5c5-3e1c37f57a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm glad you asked!\\n\\nBased on your climate and region (Molo), I would recommend cultivating a high-yielding, disease-resistant, and heat-tolerant potato variety that can perform well under challenging conditions. Considering these factors, here are some top potato varieties for Molo:\\n\\n1. **'Russet Burbank'**: This is one of the most widely grown potatoes in the world and is known for its high yield potential, disease resistance, and tolerance to heat stress.\\n2. **'Desiree'**: A popular variety with a reputation for being highly productive and resistant to common diseases such as late blight and potato scab.\\n3. **'Nicola'**: Another highly yielding and disease-resistant variety that is well-suited to Molo's climate, with good resistance to late blight and other major diseases.\\n\\nAll three of these varieties are known for their high yields under a wide range of conditions, including heat, drought, and disease pressure. However, the best choice for Molo will ultimately depend on your specific farm management practices, soil type, and market demand.\\n\\nHere's why:\\n\\n* **Russet Burbank**: This variety is specifically bred for its high yield potential and tolerance to heat stress, making it an excellent choice for Molo.\\n* **Desiree**: While this variety may not be as heat-tolerant as Russet Burbank, it is highly productive and resistant to late blight, making it a good option for Molo's challenging climate.\\n* **Nicola**: This variety offers high yields under various conditions, including heat stress and disease pressure, making it a versatile choice for Molo.\\n\\nWhen selecting a potato variety for your farm in Molo, I would recommend consulting with local experts or conducting field trials to determine the best options for your specific location and management practices. Additionally, consider factors such as soil type, moisture levels, and market demand when making your decision.\\n\\nI hope this helps you find the best potato variety for your farm in Molo!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generated_response = \"\"\"Target 1.1 By 2030, eradicate extreme poverty for all people everywhere, currently measured as people living on less than $1.25 a day\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"I'm glad you asked!\n",
    "\n",
    "Based on your climate and region (Molo), I would recommend cultivating a high-yielding, disease-resistant, and heat-tolerant potato variety that can perform well under challenging conditions. Considering these factors, here are some top potato varieties for Molo:\n",
    "\n",
    "1. **'Russet Burbank'**: This is one of the most widely grown potatoes in the world and is known for its high yield potential, disease resistance, and tolerance to heat stress.\n",
    "2. **'Desiree'**: A popular variety with a reputation for being highly productive and resistant to common diseases such as late blight and potato scab.\n",
    "3. **'Nicola'**: Another highly yielding and disease-resistant variety that is well-suited to Molo's climate, with good resistance to late blight and other major diseases.\n",
    "\n",
    "All three of these varieties are known for their high yields under a wide range of conditions, including heat, drought, and disease pressure. However, the best choice for Molo will ultimately depend on your specific farm management practices, soil type, and market demand.\n",
    "\n",
    "Here's why:\n",
    "\n",
    "* **Russet Burbank**: This variety is specifically bred for its high yield potential and tolerance to heat stress, making it an excellent choice for Molo.\n",
    "* **Desiree**: While this variety may not be as heat-tolerant as Russet Burbank, it is highly productive and resistant to late blight, making it a good option for Molo's challenging climate.\n",
    "* **Nicola**: This variety offers high yields under various conditions, including heat stress and disease pressure, making it a versatile choice for Molo.\n",
    "\n",
    "When selecting a potato variety for your farm in Molo, I would recommend consulting with local experts or conducting field trials to determine the best options for your specific location and management practices. Additionally, consider factors such as soil type, moisture levels, and market demand when making your decision.\n",
    "\n",
    "I hope this helps you find the best potato variety for your farm in Molo!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b083477-c443-4443-bbf7-f4f7e7589149",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_hypotheses \u001b[38;5;28;01mif\u001b[39;00m best_hypotheses \u001b[38;5;28;01melse\u001b[39;00m [(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)]\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m###################################################################################\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Print the top 3 most similar hypotheses\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Matching Hypotheses:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[0;34m(response, hypotheses)\u001b[0m\n\u001b[1;32m     19\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     20\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m label_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(\u001b[43mprobabilities\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m label \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentailment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontradiction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m][label_id]\n\u001b[1;32m     24\u001b[0m confidence_score \u001b[38;5;241m=\u001b[39m probabilities[\u001b[38;5;241m0\u001b[39m][label_id]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Convert to percentage\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import MPNetTokenizer, MPNetForSequenceClassification\n",
    "import torch\n",
    "# Load the tokenizer and pre-trained model\n",
    "model_name = \"/home/shadrack/Documents/CIPotatoe/drafts/local_models/scoring_mpnet/fine_tuned_model_with_classification_head\"  # Replace with your fine-tuned model path if applicable\n",
    "tokenizer = MPNetTokenizer.from_pretrained(model_name)\n",
    "model = MPNetForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Binary classification\n",
    "\n",
    "\n",
    "# Example input for classification\n",
    "#text = \"potatoes contribute to food security.\"\n",
    "##############################################################################\n",
    "def calculate_similarity(response, hypotheses):\n",
    "    similarities = []\n",
    "    for hypothesis in hypotheses:\n",
    "        inputs = tokenizer(response, hypothesis, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        label_id = torch.argmax(probabilities, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probabilities[0][label_id].item() * 100  # Convert to percentage\n",
    "        \n",
    "        similarities.append((hypothesis, label, confidence_score))\n",
    "    \n",
    "    # Sort by confidence and return the top matches\n",
    "    similarities = sorted(similarities, key=lambda x: x[2], reverse=True)\n",
    "    return similarities\n",
    "    #########################################################################\n",
    "def find_best_hypothesis(generated_response, hypothesis_candidates, threshold=70.0):\n",
    "    best_hypotheses = []\n",
    "    \n",
    "    for candidate in hypothesis_candidates:\n",
    "        inputs = tokenizer(text,return_tensors=\"pt\",  # Convert to PyTorch tensors\n",
    "                           padding=\"max_length\",  # Pad to the model's max sequence length\n",
    "                           truncation=True,  # Truncate longer sequences\n",
    "                           max_length=512,  # MPNet's max token limit\n",
    ")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        label_id = torch.argmax(probabilities, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probabilities[0][label_id].item() * 100  # Convert to percentage\n",
    "        \n",
    "        # Only include hypotheses with confidence scores above the threshold\n",
    "        if confidence_score >= threshold:\n",
    "            best_hypotheses.append((candidate, label, confidence_score))\n",
    "\n",
    "    # Sort by confidence score in descending order and select top matches\n",
    "    best_hypotheses = sorted(best_hypotheses, key=lambda x: x[2], reverse=True)[:3]\n",
    "    \n",
    "    return best_hypotheses if best_hypotheses else [(None, \"neutral\", 0.0)]\n",
    "    ###################################################################################\n",
    "\n",
    "similarities = calculate_similarity(generated_response, hypothesis_candidates)\n",
    "\n",
    "# Print the top 3 most similar hypotheses\n",
    "print(\"Top Matching Hypotheses:\")\n",
    "for hypothesis, label, score in similarities[:3]:  # Top 3 matches\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n",
    "# We now find the best matching hypotheses directly from the premise\n",
    "best_matches = find_best_hypothesis(generated_response, hypothesis_candidates)\n",
    "print(\"Best Matching Hypotheses based on premise:\")\n",
    "for hypothesis, label, score in best_matches:\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n",
    "########################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6f98b-ae64-45d4-9b34-52c720caa683",
   "metadata": {},
   "source": [
    "**WORKING CODE** \n",
    "**WORKING CODE**\n",
    "**WORKING CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "428dddc6-634d-4db7-a830-2921f4e8db6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matching Hypotheses:\n",
      "Hypothesis: Target 2.1 By 2030, end hunger and ensure access by all people, in particular the poor and people in vulnerable situations, including infants, to safe, nutritious and sufficient food all year round\n",
      "Label: contradiction\n",
      "Confidence Score: 94.01%\n",
      "\n",
      "Hypothesis: Target 2.5 By 2020, maintain the genetic diversity of seeds, cultivated plants and farmed and domesticated animals and their related wild species, including through soundly managed and diversified seed and plant banks at the national, regional and international levels, and promote access to and fair and equitable sharing of benefits arising from the utilization of genetic resources and associated traditional knowledge, as internationally agreed\n",
      "Label: contradiction\n",
      "Confidence Score: 92.63%\n",
      "\n",
      "Hypothesis: Target 2.4 By 2030, ensure sustainable food production systems and implement resilient agricultural practices that increase productivity and production, that help maintain ecosystems, that strengthen capacity for adaptation to climate change, extreme weather, drought, flooding and other disasters and that progressively improve land and soil quality\n",
      "Label: contradiction\n",
      "Confidence Score: 90.46%\n",
      "\n",
      "Best Matching Hypotheses based on premise:\n",
      "Hypothesis: Target 2.1 By 2030, end hunger and ensure access by all people, in particular the poor and people in vulnerable situations, including infants, to safe, nutritious and sufficient food all year round\n",
      "Label: contradiction\n",
      "Confidence Score: 94.01%\n",
      "\n",
      "Hypothesis: Target 2.5 By 2020, maintain the genetic diversity of seeds, cultivated plants and farmed and domesticated animals and their related wild species, including through soundly managed and diversified seed and plant banks at the national, regional and international levels, and promote access to and fair and equitable sharing of benefits arising from the utilization of genetic resources and associated traditional knowledge, as internationally agreed\n",
      "Label: contradiction\n",
      "Confidence Score: 92.63%\n",
      "\n",
      "Hypothesis: Target 2.4 By 2030, ensure sustainable food production systems and implement resilient agricultural practices that increase productivity and production, that help maintain ecosystems, that strengthen capacity for adaptation to climate change, extreme weather, drought, flooding and other disasters and that progressively improve land and soil quality\n",
      "Label: contradiction\n",
      "Confidence Score: 90.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import MPNetTokenizer, MPNetForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and pre-trained model\n",
    "model_name = \"/home/shadrack/Documents/CIPotatoe/drafts/local_models/scoring_mpnet/fine_tuned_model_with_classification_head\"  # Replace with your fine-tuned model path if applicable\n",
    "tokenizer = MPNetTokenizer.from_pretrained(model_name)\n",
    "model = MPNetForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Multi-class classification\n",
    "\n",
    "# Example input for classification\n",
    "generated_response = \"\"\"Potato variety is resistant to late blight\"\"\"\n",
    "#hypothesis_candidates\n",
    "\n",
    "##############################################################################\n",
    "def calculate_similarity(response, hypotheses):\n",
    "    similarities = []\n",
    "    for hypothesis in hypotheses:\n",
    "        inputs = tokenizer(response, hypothesis, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        label_id = torch.argmax(probabilities, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probabilities[0][label_id].item() * 100  # Convert to percentage\n",
    "\n",
    "        similarities.append((hypothesis, label, confidence_score))\n",
    "\n",
    "    # Sort by confidence and return the top matches\n",
    "    similarities = sorted(similarities, key=lambda x: x[2], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "##############################################################################\n",
    "def find_best_hypothesis(response, hypotheses, threshold=20.0):\n",
    "    best_hypotheses = []\n",
    "\n",
    "    for hypothesis in hypotheses:\n",
    "        inputs = tokenizer(response, hypothesis, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        label_id = torch.argmax(probabilities, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probabilities[0][label_id].item() * 100  # Convert to percentage\n",
    "\n",
    "        # Only include hypotheses with confidence scores above the threshold\n",
    "        if confidence_score >= threshold:\n",
    "            best_hypotheses.append((hypothesis, label, confidence_score))\n",
    "\n",
    "    # Sort by confidence score in descending order and select top matches\n",
    "    best_hypotheses = sorted(best_hypotheses, key=lambda x: x[2], reverse=True)[:3]\n",
    "\n",
    "    return best_hypotheses if best_hypotheses else [(None, \"neutral\", 0.0)]\n",
    "\n",
    "##############################################################################\n",
    "# Compute similarities\n",
    "similarities = calculate_similarity(generated_response, hypothesis_candidates)\n",
    "\n",
    "# Print the top 3 most similar hypotheses\n",
    "print(\"Top Matching Hypotheses:\")\n",
    "for hypothesis, label, score in similarities[:3]:  # Top 3 matches\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n",
    "# Find the best matching hypotheses directly from the premise\n",
    "best_matches = find_best_hypothesis(generated_response, hypothesis_candidates)\n",
    "print(\"Best Matching Hypotheses based on premise:\")\n",
    "for hypothesis, label, score in best_matches:\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb55b3e-291a-4883-a363-7a72c4d0e1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hypothesis', 'contradiction', 64.04078006744385)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f046e79b-c628-4205-b7fe-751cb44a7e23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m premise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is agriculture?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Step 1: Generate a response based on the premise by calling the earlier developed function\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m generated_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m(premise)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Step 2: Score the response's relevance or similarity to the hypotheses\u001b[39;00m\n\u001b[1;32m     58\u001b[0m similarities \u001b[38;5;241m=\u001b[39m calculate_similarity(generated_response, hypothesis_candidates)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_response' is not defined"
     ]
    }
   ],
   "source": [
    "##################################################################################################################################\n",
    "\n",
    "# Calculate similarity score of the generated response to the prompt\n",
    "def calculate_similarity(response, hypotheses):\n",
    "    similarities = []\n",
    "    for hypothesis in hypotheses:\n",
    "        inputs = scoring_tokenizer(response, hypothesis, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = scoring_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        label_id = torch.argmax(probs, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probs[0][label_id].item() * 100  # Convert to percentage\n",
    "        \n",
    "        similarities.append((hypothesis, label, confidence_score))\n",
    "    \n",
    "    # Sort by confidence and return the top matches\n",
    "    similarities = sorted(similarities, key=lambda x: x[2], reverse=True)\n",
    "    return similarities\n",
    "\n",
    "def find_best_hypothesis(premise, hypothesis_candidates, threshold=70.0):\n",
    "    best_hypotheses = []\n",
    "    \n",
    "    for candidate in hypothesis_candidates:\n",
    "        inputs = scoring_tokenizer(premise, candidate, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = scoring_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        label_id = torch.argmax(probs, dim=-1).item()\n",
    "        label = [\"entailment\", \"contradiction\", \"neutral\"][label_id]\n",
    "        confidence_score = probs[0][label_id].item() * 100  # Convert to percentage\n",
    "        \n",
    "        # Only include hypotheses with confidence scores above the threshold\n",
    "        if confidence_score >= threshold:\n",
    "            best_hypotheses.append((candidate, label, confidence_score))\n",
    "\n",
    "    # Sort by confidence score in descending order and select top matches\n",
    "    best_hypotheses = sorted(best_hypotheses, key=lambda x: x[2], reverse=True)[:3]\n",
    "    \n",
    "    return best_hypotheses if best_hypotheses else [(None, \"neutral\", 0.0)]\n",
    "\n",
    "\"\"\"Here we define the prompt and will latter be used or intergrated into the function calling\n",
    "Prompt engineering to be done here in the T5 model architecture\n",
    "We adjust the pemperature and the P to optimize the models output\"\"\"\n",
    "\n",
    "premise = \"What is agriculture?\"\n",
    "\n",
    "# Step 1: Generate a response based on the premise by calling the earlier developed function\n",
    "generated_response = generate_response(premise)\n",
    "\n",
    "# Step 2: Score the response's relevance or similarity to the hypotheses\n",
    "similarities = calculate_similarity(generated_response, hypothesis_candidates)\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated Response:\")\n",
    "print(f\"Response: {generated_response}\\n\")\n",
    "\n",
    "# Print the top 3 most similar hypotheses\n",
    "print(\"Top Matching Hypotheses:\")\n",
    "for hypothesis, label, score in similarities[:3]:  # Top 3 matches\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n",
    "# We now find the best matching hypotheses directly from the premise\n",
    "best_matches = find_best_hypothesis(premise, hypothesis_candidates)\n",
    "print(\"Best Matching Hypotheses based on premise:\")\n",
    "for hypothesis, label, score in best_matches:\n",
    "    print(f\"Hypothesis: {hypothesis}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Confidence Score: {score:.2f}%\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a2ae2a-e50a-4e3a-9985-6dffb9d7c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Goal 1. End poverty in all its forms everywhere\n",
      "0    Target 1.1 By 2030, eradicate extreme poverty ...\n",
      "1    Target 1.2 By 2030, reduce at least by half th...\n",
      "2    Target 1.3 Implement nationally appropriate so...\n",
      "3    Target 1.4 By 2030, ensure that all men and wo...\n",
      "4    Target 1.5 By 2030, build the resilience of th...\n",
      "..                                                 ...\n",
      "109  Target 17.5 Adopt and implement investment pro...\n",
      "110  Target 17.6 Enhance North-South, South-South a...\n",
      "111  Target 17.7 Promote the development, transfer,...\n",
      "112  Target 17.8 Fully operationalize the technolog...\n",
      "113  Target 17.9 Enhance international support for ...\n",
      "\n",
      "[114 rows x 1 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa04850d-b797-4363-b5f5-8f43ea76dd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetForSequenceClassification(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (classifier): MPNetClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57fb9f2-b423-4b75-ae05-2781e52959e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
